{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.3.1\n",
      "Torchvision Version:  0.4.2\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import pickle as cPickle\n",
    "\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data/\"\n",
    "model_name = \"vgg13\"\n",
    "num_classes = 102\n",
    "batch_size = 100\n",
    "num_epochs = 100\n",
    "feature_extract = True\n",
    "PATH_model = './model/'+model_name+'.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    acc_sum_max = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        # Each epoch has a training and validation phase\n",
    "        acc_sum = 0\n",
    "        \n",
    "        for phase in [\"train\",\"val\"]:\n",
    "#             model.load_state_dict(torch.load(PATH_model))\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "    \n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save(model.state_dict(), PATH_model)\n",
    "                print(\"saving\")\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "        \n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg13-c768596a.pth\" to /home/piggy/.cache/torch/checkpoints/vgg13-c768596a.pth\n",
      "100%|██████████| 508M/508M [00:50<00:00, 10.5MB/s] \n"
     ]
    }
   ],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet18\":\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "        \n",
    "    if model_name == \"resnet34\":\n",
    "        model_ft = models.resnet34(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "        \n",
    "    if model_name == \"resnet50\":\n",
    "        model_ft = models.resnet50(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "        \n",
    "    if model_name == \"resnet101\":\n",
    "        model_ft = models.resnet101(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "    \n",
    "    if model_name == \"resnet152\":\n",
    "        model_ft = models.resnet152(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "        \n",
    "    elif model_name == \"vgg13\":\n",
    "        model_ft = models.vgg13(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "        \n",
    "    elif model_name == \"vgg16\":\n",
    "        model_ft = models.vgg16(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "        \n",
    "    elif model_name == \"vgg19\":\n",
    "        model_ft = models.vgg19(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet11\":\n",
    "        model_ft = models.squeezenet1_1(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet121\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inceptionv3\":\n",
    "        \"\"\" Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size\n",
    "\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "import torchvision.transforms.functional as TF\n",
    "import random\n",
    "\n",
    "angle = random.choice([-30, -15, 0, 15, 30])\n",
    "# img = TF.rotate(img, angle)\n",
    "\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.RandomRotation(45, resample=False, expand=False, center=None),\n",
    "        transforms.ColorJitter(brightness=0.7, contrast=0.7, saturation=0.7, hue=0),\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val','test']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val','test']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t classifier.6.weight\n",
      "\t classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "# Send the model to GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(params_to_update, lr=0.06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "----------\n",
      "train Loss: 33.5951 Acc: 0.1373\n",
      "val Loss: 24.3391 Acc: 0.2412\n",
      "saving\n",
      "Epoch 1/99\n",
      "----------\n",
      "train Loss: 21.7643 Acc: 0.3725\n",
      "val Loss: 14.8416 Acc: 0.4627\n",
      "saving\n",
      "Epoch 2/99\n",
      "----------\n",
      "train Loss: 15.7344 Acc: 0.4922\n",
      "val Loss: 10.9215 Acc: 0.5422\n",
      "saving\n",
      "Epoch 3/99\n",
      "----------\n",
      "train Loss: 11.0168 Acc: 0.5608\n",
      "val Loss: 9.3219 Acc: 0.6049\n",
      "saving\n",
      "Epoch 4/99\n",
      "----------\n",
      "train Loss: 9.8177 Acc: 0.6157\n",
      "val Loss: 11.1312 Acc: 0.5794\n",
      "Epoch 5/99\n",
      "----------\n",
      "train Loss: 10.7632 Acc: 0.6000\n",
      "val Loss: 9.7432 Acc: 0.6127\n",
      "saving\n",
      "Epoch 6/99\n",
      "----------\n",
      "train Loss: 11.3976 Acc: 0.6186\n",
      "val Loss: 10.6542 Acc: 0.6000\n",
      "Epoch 7/99\n",
      "----------\n",
      "train Loss: 10.8950 Acc: 0.6324\n",
      "val Loss: 10.3624 Acc: 0.6343\n",
      "saving\n",
      "Epoch 8/99\n",
      "----------\n",
      "train Loss: 9.8564 Acc: 0.6618\n",
      "val Loss: 10.6869 Acc: 0.6304\n",
      "Epoch 9/99\n",
      "----------\n",
      "train Loss: 9.8238 Acc: 0.6725\n",
      "val Loss: 10.9018 Acc: 0.6392\n",
      "saving\n",
      "Epoch 10/99\n",
      "----------\n",
      "train Loss: 11.2253 Acc: 0.6529\n",
      "val Loss: 11.4909 Acc: 0.6343\n",
      "Epoch 11/99\n",
      "----------\n",
      "train Loss: 9.9191 Acc: 0.6637\n",
      "val Loss: 10.8643 Acc: 0.6510\n",
      "saving\n",
      "Epoch 12/99\n",
      "----------\n",
      "train Loss: 10.6681 Acc: 0.6725\n",
      "val Loss: 10.3926 Acc: 0.6627\n",
      "saving\n",
      "Epoch 13/99\n",
      "----------\n",
      "train Loss: 9.8462 Acc: 0.6980\n",
      "val Loss: 11.9527 Acc: 0.6500\n",
      "Epoch 14/99\n",
      "----------\n",
      "train Loss: 9.9035 Acc: 0.7147\n",
      "val Loss: 11.8912 Acc: 0.6539\n",
      "Epoch 15/99\n",
      "----------\n",
      "train Loss: 9.1159 Acc: 0.7069\n",
      "val Loss: 10.8587 Acc: 0.6696\n",
      "saving\n",
      "Epoch 16/99\n",
      "----------\n",
      "train Loss: 8.3971 Acc: 0.7216\n",
      "val Loss: 13.9033 Acc: 0.6441\n",
      "Epoch 17/99\n",
      "----------\n",
      "train Loss: 10.1709 Acc: 0.6892\n",
      "val Loss: 11.6569 Acc: 0.6755\n",
      "saving\n",
      "Epoch 18/99\n",
      "----------\n",
      "train Loss: 9.3223 Acc: 0.7206\n",
      "val Loss: 11.9214 Acc: 0.6745\n",
      "Epoch 19/99\n",
      "----------\n",
      "train Loss: 8.4902 Acc: 0.7441\n",
      "val Loss: 12.2141 Acc: 0.6814\n",
      "saving\n",
      "Epoch 20/99\n",
      "----------\n",
      "train Loss: 9.7000 Acc: 0.7039\n",
      "val Loss: 11.6299 Acc: 0.6775\n",
      "Epoch 21/99\n",
      "----------\n",
      "train Loss: 8.9985 Acc: 0.7382\n",
      "val Loss: 12.8520 Acc: 0.6725\n",
      "Epoch 22/99\n",
      "----------\n",
      "train Loss: 8.3692 Acc: 0.7569\n",
      "val Loss: 12.6191 Acc: 0.6735\n",
      "Epoch 23/99\n",
      "----------\n",
      "train Loss: 9.1980 Acc: 0.7549\n",
      "val Loss: 13.9280 Acc: 0.6735\n",
      "Epoch 24/99\n",
      "----------\n",
      "train Loss: 9.0477 Acc: 0.7598\n",
      "val Loss: 13.7395 Acc: 0.6716\n",
      "Epoch 25/99\n",
      "----------\n",
      "train Loss: 8.8831 Acc: 0.7667\n",
      "val Loss: 14.0784 Acc: 0.6706\n",
      "Epoch 26/99\n",
      "----------\n",
      "train Loss: 9.6396 Acc: 0.7441\n",
      "val Loss: 12.3799 Acc: 0.6951\n",
      "saving\n",
      "Epoch 27/99\n",
      "----------\n",
      "train Loss: 9.7387 Acc: 0.7578\n",
      "val Loss: 13.4666 Acc: 0.6922\n",
      "Epoch 28/99\n",
      "----------\n",
      "train Loss: 8.0840 Acc: 0.7686\n",
      "val Loss: 14.0063 Acc: 0.6765\n",
      "Epoch 29/99\n",
      "----------\n",
      "train Loss: 8.9453 Acc: 0.7598\n",
      "val Loss: 14.1638 Acc: 0.6912\n",
      "Epoch 30/99\n",
      "----------\n",
      "train Loss: 10.0126 Acc: 0.7520\n",
      "val Loss: 13.8842 Acc: 0.6961\n",
      "saving\n",
      "Epoch 31/99\n",
      "----------\n",
      "train Loss: 8.8892 Acc: 0.7725\n",
      "val Loss: 14.9072 Acc: 0.6902\n",
      "Epoch 32/99\n",
      "----------\n",
      "train Loss: 9.8598 Acc: 0.7824\n",
      "val Loss: 15.5813 Acc: 0.6716\n",
      "Epoch 33/99\n",
      "----------\n",
      "train Loss: 8.7321 Acc: 0.7706\n",
      "val Loss: 17.1297 Acc: 0.6490\n",
      "Epoch 34/99\n",
      "----------\n",
      "train Loss: 8.5931 Acc: 0.7647\n"
     ]
    }
   ],
   "source": [
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
